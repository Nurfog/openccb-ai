# OpenCCB AI ü§ñ

**OpenCCB AI** es una API de asistente inteligente privada, local y escalable dise√±ada para entornos corporativos. Utiliza **Ollama** para ejecutar modelos de lenguaje (LLM) como Llama 3, **FastAPI** para la gesti√≥n de peticiones, **Redis** para memoria conversacional de alta velocidad y **PostgreSQL** para la gesti√≥n de usuarios y seguridad.

## üöÄ Caracter√≠sticas Principales

*   **Privacidad Total:** El modelo de IA se ejecuta localmente (On-Premise); ning√∫n dato sale de tu servidor.
*   **Streaming de Texto:** Respuestas generadas palabra por palabra en tiempo real (como ChatGPT).
*   **Memoria Contextual:** La IA recuerda lo que se habl√≥ anteriormente en la sesi√≥n gracias a Redis.
*   **Multi-Usuario:** Sistema de autenticaci√≥n y gesti√≥n de sesiones con PostgreSQL.
*   **Soporte GPU:** Detecci√≥n y configuraci√≥n autom√°tica de tarjetas NVIDIA para m√°xima velocidad.
*   **Interfaz Gr√°fica:** Frontend moderno construido con Streamlit para facilitar el uso.
*   **Multi-Modelo:** Capacidad de cambiar din√°micamente entre modelos (Llama 3, Mistral, CodeLlama, etc.).
*   **An√°lisis de Documentos:** Subida de PDFs para extracci√≥n autom√°tica de temas y puntos clave.
*   **Despliegue Automatizado:** Scripts incluidos para instalaci√≥n en servidores Ubuntu y actualizaciones remotas.

---

## üìã Requisitos del Sistema

Para un entorno de producci√≥n con ~60 usuarios concurrentes:

| Componente | M√≠nimo (Funcional) | Recomendado (Producci√≥n) |
| :--- | :--- | :--- |
| **Sistema Operativo** | Ubuntu 22.04 LTS | Ubuntu 22.04 / 24.04 LTS |
| **CPU** | 4 vCPUs | 8 vCPUs (AVX2 support) |
| **RAM** | 8 GB | **16 GB** |
| **GPU** | N/A (Modo CPU lento) | **NVIDIA (8GB+ VRAM)** |
| **Almacenamiento** | 20 GB SSD | 50 GB NVMe |

---

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

### 1. Instalaci√≥n en Servidor (Producci√≥n)

El proyecto incluye un script maestro (`setup.sh`) que automatiza la instalaci√≥n de Docker, Drivers de NVIDIA, Nginx y la configuraci√≥n de seguridad.

```bash
# 1. Clonar el repositorio
git clone https://github.com/Nurfog/openccb-ai.git
cd openccb-ai

# 2. Ejecutar el instalador
chmod +x setup.sh
./setup.sh
```

*El script generar√° autom√°ticamente un archivo `.env` con contrase√±as seguras y levantar√° los servicios en el puerto 80 (v√≠a Nginx).*

### 2. Desarrollo Local

Si quieres ejecutarlo en tu m√°quina para programar:

1.  Copia el archivo de ejemplo:
    ```bash
    cp .env.example .env
    ```
2.  Levanta los servicios con Docker Compose:
    ```bash
    docker compose up --build
    ```
3.  La API estar√° disponible en `http://localhost:8000`.
4.  La Interfaz Web (Frontend) estar√° disponible en `http://localhost:8501`.

---

## üö¢ Gu√≠as de Despliegue (Deploy)

Este proyecto soporta dos m√©todos de despliegue remoto sin necesidad de instalar Git en el servidor de destino.

### Opci√≥n A: Despliegue v√≠a SSH (Push) - **Recomendado**
Sincroniza tu c√≥digo local con el servidor remoto y ejecuta la instalaci√≥n autom√°ticamente.

1.  Configura tus credenciales:
    ```bash
    cp ssh_deploy.example ssh_deploy.env
    # Edita ssh_deploy.env con la IP y Usuario de tu servidor
    ```
2.  Ejecuta el despliegue:
    ```bash
    chmod +x ssh_deploy.sh
    ./ssh_deploy.sh
    ```

### Opci√≥n B: Despliegue v√≠a FTP (Pull)
√ötil si tienes el c√≥digo empaquetado en un servidor FTP intermedio.

1.  Configura el acceso FTP:
    ```bash
    cp deploy.example deploy.env
    # Edita deploy.env
    ```
2.  Ejecuta el script en el servidor destino:
    ```bash
    chmod +x deploy.sh
    ./deploy.sh
    ```

---

## üîå Documentaci√≥n de la API

### 1. Registro de Usuario
**POST** `/register`
```bash
curl -X POST "http://localhost:8000/register" \
     -H "Content-Type: application/json" \
     -d '{"username": "juan", "password": "password123"}'
```

### 2. Iniciar Sesi√≥n (Login)
**POST** `/login`
```bash
curl -X POST "http://localhost:8000/login" \
     -H "Content-Type: application/json" \
     -d '{"username": "juan", "password": "password123"}'
```

### 3. Chat con la IA (Streaming)
**POST** `/chat`

*   **Nueva Sesi√≥n:** Omite `session_id`. La API crear√° uno nuevo y generar√° un t√≠tulo autom√°tico.
*   **Continuar Sesi√≥n:** Env√≠a el `session_id` devuelto anteriormente.
*   **RAG (Base de Conocimiento):** Env√≠a `"use_kb": true` para que la IA busque en los documentos de S3.

```bash
curl -X POST "http://localhost:8000/chat" \
     -H "Content-Type: application/json" \
     -d '{
           "username": "juan",
           "prompt": "Expl√≠came qu√© es Docker en una frase",
           "session_id": "OPCIONAL_UUID_AQUI",
           "use_kb": true
         }'
```
*Respuesta:* Stream de texto plano. Al final incluye un JSON con el ID de sesi√≥n: `{"session_id": "..."}`.

### 4. Listar Sesiones
**GET** `/sessions/{username}`
```bash
curl "http://localhost:8000/sessions/juan"
```
*Respuesta:*
```json
[
  {
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "description": "Explicaci√≥n de Docker resumen"
  }
]
```

### 5. Analizar Documento
**POST** `/analyze`
```bash
curl -X POST "http://localhost:8000/analyze?model=llama3&query=Donde%20esta%20el%20procedimiento" \
     -F "file=@documento.pdf"
```
*Respuesta:* JSON con los temas principales extra√≠dos del documento.

### 6. Sincronizar Base de Conocimiento (S3)
**POST** `/s3/sync`
Descarga los PDFs del bucket S3 configurado, extrae el texto p√°gina por p√°gina e indexa el contenido en la base de datos para b√∫squedas RAG.

```bash
curl -X POST "http://localhost:8000/s3/sync"
```
*Respuesta:* JSON con la cantidad de p√°ginas sincronizadas.

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Consulta el archivo LICENSE para m√°s detalles.
